{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "582ef139",
   "metadata": {},
   "source": [
    "· Coronavirus tweets NLP - Text Classification\n",
    "\n",
    "\n",
    "Veriler üzerinde Metin Sınıflandırması gerçekleştirin. Tweetler Twitter'dan çekildi ve ardından manuel etiketleme yapıldı.\n",
    "Herhangi bir gizlilik endişesinden kaçınmak için adlara ve kullanıcı adlarına kodlar verilmiştir.\n",
    "\n",
    "Sütunlar:\n",
    "1) Konum\n",
    "2) Tweet at\n",
    "3) Orijinal Tweet\n",
    "4) Etiket\n",
    "\n",
    "https://www.kaggle.com/datasets/datatattle/covid-19-nlp-text-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbb59fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NLTK - Natural Language Toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6e8ff43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/bmaho/opt/anaconda3/lib/python3.9/site-packages (3.7)\n",
      "Requirement already satisfied: tqdm in /Users/bmaho/opt/anaconda3/lib/python3.9/site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: click in /Users/bmaho/opt/anaconda3/lib/python3.9/site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/bmaho/opt/anaconda3/lib/python3.9/site-packages (from nltk) (2022.3.15)\n",
      "Requirement already satisfied: joblib in /Users/bmaho/opt/anaconda3/lib/python3.9/site-packages (from nltk) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7481a3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import nltk\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from textblob import TextBlob\n",
    "\n",
    "import sys \n",
    "from nltk.stem import SnowballStemmer\n",
    "from langdetect import detect\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a723cc",
   "metadata": {},
   "source": [
    "''''# NLP Projesi icin yapmamiz gerekenler\n",
    "1-Herseyi kucuk harfe cevir\n",
    "2-Noktalama isaretlerini kaldir\n",
    "3-Rakamlari kaldir\n",
    "4-satir sonlari \\n kaldir\n",
    "5- Gereksiz kelimeleri cikar Stopword\n",
    "6-Tokenize islemi\n",
    "7-Lemma ve Stemma\n",
    "8 - Vectorizer rakama ceviriyor'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33099978",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1= pd.read_csv(\"Corona_NLP_train.csv\" ,encoding='latin-1' , sep=',' )\n",
    "df2 = pd.read_csv(\"Corona_NLP_test.csv\" , encoding='latin-1' ,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3760b845",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.drop([\"UserName\" , \"ScreenName\" , \"Location\"] , axis = 1 , inplace = True)\n",
    "df2.drop([\"UserName\" , \"ScreenName\" , \"Location\"], axis = 1 , inplace = True)\n",
    "#kişi ismi, kullanıcı adı, yer bilgilerini veri setinden sildik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f920b61f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41157 entries, 0 to 41156\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   TweetAt        41157 non-null  object\n",
      " 1   OriginalTweet  41157 non-null  object\n",
      " 2   Sentiment      41157 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 964.7+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3798 entries, 0 to 3797\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   TweetAt        3798 non-null   object\n",
      " 1   OriginalTweet  3798 non-null   object\n",
      " 2   Sentiment      3798 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 89.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df1.info())\n",
    "print(df2.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0c8559b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive              11422\n",
       "Negative               9917\n",
       "Neutral                7713\n",
       "Extremely Positive     6624\n",
       "Extremely Negative     5481\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[\"Sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f001843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Negative              1041\n",
       "Positive               947\n",
       "Neutral                619\n",
       "Extremely Positive     599\n",
       "Extremely Negative     592\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[\"Sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9e43ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: category_encoders in /Users/bmaho/opt/anaconda3/lib/python3.9/site-packages (2.6.0)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in /Users/bmaho/opt/anaconda3/lib/python3.9/site-packages (from category_encoders) (0.13.2)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /Users/bmaho/opt/anaconda3/lib/python3.9/site-packages (from category_encoders) (1.1.2)\n",
      "Requirement already satisfied: patsy>=0.5.1 in /Users/bmaho/opt/anaconda3/lib/python3.9/site-packages (from category_encoders) (0.5.2)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /Users/bmaho/opt/anaconda3/lib/python3.9/site-packages (from category_encoders) (1.21.5)\n",
      "Requirement already satisfied: pandas>=1.0.5 in /Users/bmaho/opt/anaconda3/lib/python3.9/site-packages (from category_encoders) (1.4.2)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /Users/bmaho/opt/anaconda3/lib/python3.9/site-packages (from category_encoders) (1.7.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/bmaho/opt/anaconda3/lib/python3.9/site-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/bmaho/opt/anaconda3/lib/python3.9/site-packages (from pandas>=1.0.5->category_encoders) (2021.3)\n",
      "Requirement already satisfied: six in /Users/bmaho/opt/anaconda3/lib/python3.9/site-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/bmaho/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.20.0->category_encoders) (2.2.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /Users/bmaho/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.20.0->category_encoders) (1.1.0)\n",
      "Requirement already satisfied: packaging>=21.3 in /Users/bmaho/opt/anaconda3/lib/python3.9/site-packages (from statsmodels>=0.9.0->category_encoders) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/bmaho/opt/anaconda3/lib/python3.9/site-packages (from packaging>=21.3->statsmodels>=0.9.0->category_encoders) (3.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f776cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f443a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "maplist = [{'col': 'Sentiment', 'mapping': {'Extremely Negative': 0, 'Negative': 1,'Neutral': 2, 'Positive': 3, 'Extremely Positive': 4}}]\n",
    "enc = OrdinalEncoder(mapping=maplist)\n",
    "df1 = enc.fit_transform(df1)\n",
    "df2 = enc.transform(df2) #sentiment analizi sonuçlarına sayısal değer atadık\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37c66290",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain = df1[\"Sentiment\"]\n",
    "ytest = df2[\"Sentiment\"]\n",
    "\n",
    "xtrain = df1.drop(\"Sentiment\" , axis = 1)\n",
    "xtest = df2.drop(\"Sentiment\" , axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2dd46c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2\n",
       "1        3\n",
       "2        3\n",
       "3        3\n",
       "4        0\n",
       "        ..\n",
       "41152    2\n",
       "41153    0\n",
       "41154    3\n",
       "41155    2\n",
       "41156    1\n",
       "Name: Sentiment, Length: 41157, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "725426fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    " # 'Türler' sütunundaki etiketleri kodladık\n",
    "\n",
    "xtrain['TweetAt']= label_encoder.fit_transform(xtrain['TweetAt'])\n",
    "xtest['TweetAt']= label_encoder.fit_transform(xtest['TweetAt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f454bfbf",
   "metadata": {},
   "source": [
    "# NLP Veri Ön Hazırlıkları"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba1e79c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3x/n1kkdkgn5m9c3thf3ctlb_xm0000gn/T/ipykernel_5009/371967069.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df1['OriginalTweet']=df1['OriginalTweet'].str.replace('[^\\w\\s]','') # Noktalama isaretlerini kaldirir\n",
      "/var/folders/3x/n1kkdkgn5m9c3thf3ctlb_xm0000gn/T/ipykernel_5009/371967069.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df1['OriginalTweett']=df1['OriginalTweet'].str.replace('\\d+','') # Rakamlari kaldirir\n"
     ]
    }
   ],
   "source": [
    "df1['OriginalTweet']=df1['OriginalTweet'].str.lower() #Butun sutunu kucuk harfe cevirir\n",
    "df1['OriginalTweet']=df1['OriginalTweet'].str.replace('[^\\w\\s]','') # Noktalama isaretlerini kaldirir\n",
    "df1['OriginalTweett']=df1['OriginalTweet'].str.replace('\\d+','') # Rakamlari kaldirir\n",
    "df1['OriginalTweet']=df1['OriginalTweet'].str.replace('\\n','') # yeni satirlari kaldir\n",
    "df1['OriginalTweet']=df1['OriginalTweet'].str.replace('\\r','') #Enter i kaldir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72c1465e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3x/n1kkdkgn5m9c3thf3ctlb_xm0000gn/T/ipykernel_5009/3888126497.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df2['OriginalTweet']=df2['OriginalTweet'].str.replace('[^\\w\\s]','') # Noktalama isaretlerini kaldirir\n",
      "/var/folders/3x/n1kkdkgn5m9c3thf3ctlb_xm0000gn/T/ipykernel_5009/3888126497.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df2['OriginalTweett']=df2['OriginalTweet'].str.replace('\\d+','') # Rakamlari kaldirir\n"
     ]
    }
   ],
   "source": [
    "df2['OriginalTweet']=df2['OriginalTweet'].str.lower() #Butun sutunu kucuk harfe cevirir\n",
    "df2['OriginalTweet']=df2['OriginalTweet'].str.replace('[^\\w\\s]','') # Noktalama isaretlerini kaldirir\n",
    "df2['OriginalTweett']=df2['OriginalTweet'].str.replace('\\d+','') # Rakamlari kaldirir\n",
    "df2['OriginalTweet']=df2['OriginalTweet'].str.replace('\\n','') # yeni satirlari kaldir\n",
    "df2['OriginalTweet']=df2['OriginalTweet'].str.replace('\\r','') #Enter i kaldir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a917e7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>OriginalTweett</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>menyrbie phil_gahan chrisitv httpstcoifz9fan2p...</td>\n",
       "      <td>2</td>\n",
       "      <td>menyrbie phil_gahan chrisitv httpstcoifzfanpa ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>advice talk to your neighbours family to excha...</td>\n",
       "      <td>3</td>\n",
       "      <td>advice talk to your neighbours family to excha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>coronavirus australia woolworths to give elder...</td>\n",
       "      <td>3</td>\n",
       "      <td>coronavirus australia woolworths to give elder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>my food stock is not the only one which is emp...</td>\n",
       "      <td>3</td>\n",
       "      <td>my food stock is not the only one which is emp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>me ready to go at supermarket during the covid...</td>\n",
       "      <td>0</td>\n",
       "      <td>me ready to go at supermarket during the covid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TweetAt                                      OriginalTweet  Sentiment  \\\n",
       "0  16-03-2020  menyrbie phil_gahan chrisitv httpstcoifz9fan2p...          2   \n",
       "1  16-03-2020  advice talk to your neighbours family to excha...          3   \n",
       "2  16-03-2020  coronavirus australia woolworths to give elder...          3   \n",
       "3  16-03-2020  my food stock is not the only one which is emp...          3   \n",
       "4  16-03-2020  me ready to go at supermarket during the covid...          0   \n",
       "\n",
       "                                      OriginalTweett  \n",
       "0  menyrbie phil_gahan chrisitv httpstcoifzfanpa ...  \n",
       "1  advice talk to your neighbours family to excha...  \n",
       "2  coronavirus australia woolworths to give elder...  \n",
       "3  my food stock is not the only one which is emp...  \n",
       "4  me ready to go at supermarket during the covid...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f310d7e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>OriginalTweett</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>menyrbie phil_gahan chrisitv httpstcoifz9fan2p...</td>\n",
       "      <td>2</td>\n",
       "      <td>menyrbie phil_gahan chrisitv httpstcoifzfanpa ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>advice talk to your neighbours family to excha...</td>\n",
       "      <td>3</td>\n",
       "      <td>advice talk to your neighbours family to excha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>coronavirus australia woolworths to give elder...</td>\n",
       "      <td>3</td>\n",
       "      <td>coronavirus australia woolworths to give elder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>my food stock is not the only one which is emp...</td>\n",
       "      <td>3</td>\n",
       "      <td>my food stock is not the only one which is emp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>me ready to go at supermarket during the covid...</td>\n",
       "      <td>0</td>\n",
       "      <td>me ready to go at supermarket during the covid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41152</th>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>airline pilots offering to stock supermarket s...</td>\n",
       "      <td>2</td>\n",
       "      <td>airline pilots offering to stock supermarket s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41153</th>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>response to complaint not provided citing covi...</td>\n",
       "      <td>0</td>\n",
       "      <td>response to complaint not provided citing covi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41154</th>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>you know itâs getting tough when kameronwilds ...</td>\n",
       "      <td>3</td>\n",
       "      <td>you know itâs getting tough when kameronwilds ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41155</th>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>is it wrong that the smell of hand sanitizer i...</td>\n",
       "      <td>2</td>\n",
       "      <td>is it wrong that the smell of hand sanitizer i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41156</th>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>tartiicat well newused rift s are going for 70...</td>\n",
       "      <td>1</td>\n",
       "      <td>tartiicat well newused rift s are going for  o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41157 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          TweetAt                                      OriginalTweet  \\\n",
       "0      16-03-2020  menyrbie phil_gahan chrisitv httpstcoifz9fan2p...   \n",
       "1      16-03-2020  advice talk to your neighbours family to excha...   \n",
       "2      16-03-2020  coronavirus australia woolworths to give elder...   \n",
       "3      16-03-2020  my food stock is not the only one which is emp...   \n",
       "4      16-03-2020  me ready to go at supermarket during the covid...   \n",
       "...           ...                                                ...   \n",
       "41152  14-04-2020  airline pilots offering to stock supermarket s...   \n",
       "41153  14-04-2020  response to complaint not provided citing covi...   \n",
       "41154  14-04-2020  you know itâs getting tough when kameronwilds ...   \n",
       "41155  14-04-2020  is it wrong that the smell of hand sanitizer i...   \n",
       "41156  14-04-2020  tartiicat well newused rift s are going for 70...   \n",
       "\n",
       "       Sentiment                                     OriginalTweett  \n",
       "0              2  menyrbie phil_gahan chrisitv httpstcoifzfanpa ...  \n",
       "1              3  advice talk to your neighbours family to excha...  \n",
       "2              3  coronavirus australia woolworths to give elder...  \n",
       "3              3  my food stock is not the only one which is emp...  \n",
       "4              0  me ready to go at supermarket during the covid...  \n",
       "...          ...                                                ...  \n",
       "41152          2  airline pilots offering to stock supermarket s...  \n",
       "41153          0  response to complaint not provided citing covi...  \n",
       "41154          3  you know itâs getting tough when kameronwilds ...  \n",
       "41155          2  is it wrong that the smell of hand sanitizer i...  \n",
       "41156          1  tartiicat well newused rift s are going for  o...  \n",
       "\n",
       "[41157 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c213b76d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41157, 4)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e5f8ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>OriginalTweett</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02-03-2020</td>\n",
       "      <td>trending new yorkers encounter empty supermark...</td>\n",
       "      <td>0</td>\n",
       "      <td>trending new yorkers encounter empty supermark...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02-03-2020</td>\n",
       "      <td>when i couldnt find hand sanitizer at fred mey...</td>\n",
       "      <td>3</td>\n",
       "      <td>when i couldnt find hand sanitizer at fred mey...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02-03-2020</td>\n",
       "      <td>find out how you can protect yourself and love...</td>\n",
       "      <td>4</td>\n",
       "      <td>find out how you can protect yourself and love...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02-03-2020</td>\n",
       "      <td>panic buying hits newyork city as anxious shop...</td>\n",
       "      <td>1</td>\n",
       "      <td>panic buying hits newyork city as anxious shop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03-03-2020</td>\n",
       "      <td>toiletpaper dunnypaper coronavirus coronavirus...</td>\n",
       "      <td>2</td>\n",
       "      <td>toiletpaper dunnypaper coronavirus coronavirus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3793</th>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>meanwhile in a supermarket in israel  people d...</td>\n",
       "      <td>3</td>\n",
       "      <td>meanwhile in a supermarket in israel  people d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3794</th>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>did you panic buy a lot of nonperishable items...</td>\n",
       "      <td>1</td>\n",
       "      <td>did you panic buy a lot of nonperishable items...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3795</th>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>asst prof of economics cconces was on nbcphila...</td>\n",
       "      <td>2</td>\n",
       "      <td>asst prof of economics cconces was on nbcphila...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3796</th>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>gov need to do somethings instead of biar je r...</td>\n",
       "      <td>0</td>\n",
       "      <td>gov need to do somethings instead of biar je r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3797</th>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>i and forestandpaper members are committed to ...</td>\n",
       "      <td>4</td>\n",
       "      <td>i and forestandpaper members are committed to ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3798 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         TweetAt                                      OriginalTweet  \\\n",
       "0     02-03-2020  trending new yorkers encounter empty supermark...   \n",
       "1     02-03-2020  when i couldnt find hand sanitizer at fred mey...   \n",
       "2     02-03-2020  find out how you can protect yourself and love...   \n",
       "3     02-03-2020  panic buying hits newyork city as anxious shop...   \n",
       "4     03-03-2020  toiletpaper dunnypaper coronavirus coronavirus...   \n",
       "...          ...                                                ...   \n",
       "3793  16-03-2020  meanwhile in a supermarket in israel  people d...   \n",
       "3794  16-03-2020  did you panic buy a lot of nonperishable items...   \n",
       "3795  16-03-2020  asst prof of economics cconces was on nbcphila...   \n",
       "3796  16-03-2020  gov need to do somethings instead of biar je r...   \n",
       "3797  16-03-2020  i and forestandpaper members are committed to ...   \n",
       "\n",
       "      Sentiment                                     OriginalTweett  \n",
       "0             0  trending new yorkers encounter empty supermark...  \n",
       "1             3  when i couldnt find hand sanitizer at fred mey...  \n",
       "2             4  find out how you can protect yourself and love...  \n",
       "3             1  panic buying hits newyork city as anxious shop...  \n",
       "4             2  toiletpaper dunnypaper coronavirus coronavirus...  \n",
       "...         ...                                                ...  \n",
       "3793          3  meanwhile in a supermarket in israel  people d...  \n",
       "3794          1  did you panic buy a lot of nonperishable items...  \n",
       "3795          2  asst prof of economics cconces was on nbcphila...  \n",
       "3796          0  gov need to do somethings instead of biar je r...  \n",
       "3797          4  i and forestandpaper members are committed to ...  \n",
       "\n",
       "[3798 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c52ebc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "600f247d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>00am</th>\n",
       "      <th>00pm</th>\n",
       "      <th>01</th>\n",
       "      <th>03</th>\n",
       "      <th>04</th>\n",
       "      <th>06</th>\n",
       "      <th>07</th>\n",
       "      <th>08</th>\n",
       "      <th>...</th>\n",
       "      <th>yyc</th>\n",
       "      <th>yâ</th>\n",
       "      <th>zambia</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zero</th>\n",
       "      <th>zimbabwe</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zombies</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41152</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41153</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41154</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41155</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41156</th>\n",
       "      <td>0.401379</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41157 rows × 8000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             00  000  00am  00pm   01   03   04   06   07   08  ...  yyc   yâ  \\\n",
       "0      0.000000  0.0   0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "1      0.000000  0.0   0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "2      0.000000  0.0   0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "3      0.000000  0.0   0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "4      0.000000  0.0   0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "...         ...  ...   ...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "41152  0.000000  0.0   0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "41153  0.000000  0.0   0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "41154  0.000000  0.0   0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "41155  0.000000  0.0   0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "41156  0.401379  0.0   0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "\n",
       "       zambia  zealand  zero  zimbabwe  zombie  zombies  zone  zoom  \n",
       "0         0.0      0.0   0.0       0.0     0.0      0.0   0.0   0.0  \n",
       "1         0.0      0.0   0.0       0.0     0.0      0.0   0.0   0.0  \n",
       "2         0.0      0.0   0.0       0.0     0.0      0.0   0.0   0.0  \n",
       "3         0.0      0.0   0.0       0.0     0.0      0.0   0.0   0.0  \n",
       "4         0.0      0.0   0.0       0.0     0.0      0.0   0.0   0.0  \n",
       "...       ...      ...   ...       ...     ...      ...   ...   ...  \n",
       "41152     0.0      0.0   0.0       0.0     0.0      0.0   0.0   0.0  \n",
       "41153     0.0      0.0   0.0       0.0     0.0      0.0   0.0   0.0  \n",
       "41154     0.0      0.0   0.0       0.0     0.0      0.0   0.0   0.0  \n",
       "41155     0.0      0.0   0.0       0.0     0.0      0.0   0.0   0.0  \n",
       "41156     0.0      0.0   0.0       0.0     0.0      0.0   0.0   0.0  \n",
       "\n",
       "[41157 rows x 8000 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=8000)\n",
    "bow_train = vectorizer.fit_transform(xtrain[\"OriginalTweet\"])\n",
    "features = vectorizer.get_feature_names_out()\n",
    "xtrain_bow=pd.DataFrame(bow_train.toarray(), columns = features)\n",
    "xtrain_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29e84b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000000    41134\n",
       "0.311651        1\n",
       "0.264563        1\n",
       "0.258502        1\n",
       "0.257087        1\n",
       "0.309607        1\n",
       "0.246882        1\n",
       "0.234649        1\n",
       "0.222425        1\n",
       "0.227430        1\n",
       "0.225887        1\n",
       "0.300836        1\n",
       "0.270933        1\n",
       "0.261711        1\n",
       "0.234287        1\n",
       "0.226250        1\n",
       "0.280613        1\n",
       "0.341972        1\n",
       "0.335291        1\n",
       "0.358021        1\n",
       "0.290574        1\n",
       "0.285685        1\n",
       "0.225633        1\n",
       "0.384936        1\n",
       "Name: zone, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_bow[\"zone\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "934d864f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_test = vectorizer.transform(xtest[\"OriginalTweet\"])\n",
    "features = vectorizer.get_feature_names_out()\n",
    "xtest_bow=pd.DataFrame(bow_test.toarray(), columns = features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ecc31db",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_bow  = pd.concat([xtrain[\"TweetAt\"], xtrain_bow] , axis =1)\n",
    "xtest_bow  = pd.concat([xtest[\"TweetAt\"], xtest_bow] , axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b33bd513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3798, 4)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2279652d",
   "metadata": {},
   "outputs": [],
   "source": [
    "star=df[(df.stars==1)|(df.stars==5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f18562",
   "metadata": {},
   "outputs": [],
   "source": [
    "star.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6841ffe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "from sklearn.svm import SVC\n",
    "svm = SVC() #makine öğrenmesi algoritmalarını çağırdık"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "baccd8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "84071a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "l=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "46616a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d32566bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bmaho/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.fit(xtrain_bow,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4ebbd037",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=l.predict(xtest_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "347e505a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41311216429699843"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(pred,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "126936dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "faa0e502",
   "metadata": {},
   "outputs": [],
   "source": [
    "m=MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9da99e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2=m.fit(xtrain_bow,ytrain).predict(xtest_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dc3da501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42706687730384413"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(pred2,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de215297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultinomialNB de 0.42 çıktı\n",
    "# Lojistik Regresyonda 0.41 çıktı\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
